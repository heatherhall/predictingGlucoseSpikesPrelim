---
title: "Data mining"
author: "Heather Hall"
date: 2015-08-05
output: html_document
---

<!-- The file analysis/chunks.R contains chunks that define default settings
shared across the workflowr files. -->
```{r read-chunk, include=FALSE, cache=FALSE}
knitr::read_chunk("chunks.R")
```

<!-- Update knitr chunk options -->
```{r knitr-opts-chunk, include=FALSE}
```

<!-- Insert the date the file was last updated -->
```{r last-updated, echo=FALSE, results='asis'}
```

<!-- Insert the code version (Git commit SHA1) if Git repository exists and R
 package git2r is installed -->
```{r code-version, echo=FALSE, results='asis'}
```

<!-- Add your analysis here -->
<!-- Add your analysis here -->
```{r preprocessingCode, message = F, include = F}


########################################################
#   Libraries
########################################################
rm(list = ls())


library("lubridate")

# # library for classification
library("leaps") # regsubset
library("kknn")
library("gbm")
library("randomForest")

# visualization
library(gridExtra); library(grid); library(gtable)
library("ggplot2")

personal.library.directory = "/Users/hhall/predictingGlucoseSpikesPrelim/code"
source(paste(personal.library.directory, "project_library.R", sep = "/"))

########################################################
### Read in Files
########################################################


# file paths
# ------------
food.data.path =  "/Users/hhall/predictingGlucoseSpikesPrelim_data/foodLogs.csv"
conversion.chart.path = "/Users/hhall/predictingGlucoseSpikesPrelim_data/food_chart.txt"
glucose.file = "/Users/hhall/predictingGlucoseSpikesPrelim_data/glucose_data_R.txt"
travel.file = "/Users/hhall/predictingGlucoseSpikesPrelim_data/flight_times_July.txt"
TZ.path = "/Users/hhall/predictingGlucoseSpikesPrelim_data/timezone_codes.txt"
food.timing.file = "/Users/hhall/predictingGlucoseSpikesPrelim_data/food_timing.txt"



# read in myfitnesspal data and recorded meal timing
food.logs = readMyFitnessPal(food.data.path, conversion.chart.path)
food.times <- read.delim(food.timing.file, stringsAsFactors = FALSE)

# read in glucose data
cgm.readings = readDexcomFile(glucose.file)


########################################################
### Data nnotation: Mark min and max peaks for all data
########################################################

min.peak = 120
min.peak.height = 30
cgm.readings = markGlucosePeaks(cgm.readings, min.peak.height, min.peak)


########################################################
### Data exclusion: only keep dates with recorded meal times
########################################################

# keep only dates with recorded meal times
dates.with.meal.times <- unique(food.times$Date)
cgm.readings <- cgm.readings[which(cgm.readings$GlucoseDisplayDate %in% dates.with.meal.times),] ### Have 14373 glucose readings with timestamped foods

########################################################
### Data exclusion -- remove travel dates because sensor time is unreliable switching time zones
########################################################

# remove travel from glucose data and food.times
cgm.readings = removeTravelDates(cgm.readings, travel.file, TZ.path)
food.times = food.times[food.times$Date %in% cgm.readings$GlucoseDisplayDate, ]

# combine features from food log with food timing
food.times = addDietaryFeatures(food.times, food.logs)

# associate glucose spikes with food features
cgm.meal.features <- associateFoodAndCGM(cgm.readings, food.times)

# remove peaks without meals
cgm.meal.features = removePeaksWithoutMeals(cgm.meal.features)


## remove variables that wont be used for prediction
features = c("timeChange","carbohydrates","glycemicIndex", 
                       "AM","fruit","grain","inulin","banana",     
                        "wine","last_meal_TIME" ,"diversity")
predictors <- cgm.meal.features[,names(cgm.meal.features) %in% features]

# define a data frame with predictors and response
outcome.predictors = cbind(cgm.meal.features$glucoseChange, predictors)

```
</br>
# Correlations between predictors
```{r determineCorrelations}

all.correlations = data.frame(matrix(ncol = 4, nrow = 1))
names(all.correlations) = c("term one", "term two", "correlation coefficient", "Bonferonni P-value")

# determine correlations 
for(i in 1:ncol(predictors)){
  for (j in 2:ncol(predictors)){
    test <- cor.test(predictors[,i],predictors[,j])
    p.value <- p.adjust(test$p.value, method="bonferroni", n = length(predictors)-1)
    if (p.value < 0.05 & i != j){
      new.row = data.frame(matrix(c(names(predictors)[i], names(predictors)[j], round(test$estimate, 2), signif(p.value, digits = 3)),
                       nrow = 1))
      names(new.row) = c("term one", "term two", "correlation coefficient", "Bonferonni P-value")
      all.correlations = rbind(all.correlations, new.row)
    }
  }
}

```

### correlation table
```{r correlation table, collapse = T}
all.correlations = all.correlations[-1,]
strong.correlations = all.correlations[abs(as.numeric(all.correlations$`correlation coefficient`)) > 0.5,]
cor.results = data.frame(strong.correlations)

# plot the RMSE for comparison
grid.newpage()
table.plot = tableGrob(cor.results, rows = NULL)
table.plot <- gtable_add_grob(table.plot,
                     grobs = rectGrob(gp = gpar(fill = NA, lwd = 2)),
                     t = 2, b = nrow(table.plot), l = 1, r = ncol(table.plot))
table.plot <- gtable_add_grob(table.plot,
                     grobs = rectGrob(gp = gpar(fill = NA, lwd = 2)),
                     t = 1, l = 1, r = ncol(table.plot))
grid.draw(table.plot)
```



# Format feature matrix
```{r formatFeatureMatrix}
# scale the predictors and convert back to dataframe
response_predictors <- data.frame(scale(predictors))

# add the response column
response_predictors$glucoseChange <- cgm.meal.features$glucoseChange
```

# Define training and test sets
```{r defineTrainingTest}
# define the training set to a random selection of 75% of the data
set.seed(1)
train = sample(1:nrow(response_predictors), nrow(response_predictors)*0.75)
test = (-train)
test.set = as.data.frame(response_predictors[test,])
train.set = as.data.frame(response_predictors[train,])


print(paste(c(nrow(test.set), " test samples, ", nrow(train.set), " training samples"), collapse = ""))
```

</br>

# Linear Regression



### Best subset selection
```{r bestsubset, collapse = T, message = F}
# 2 linear redundancies found so can only have ncol(response_predictors)- 2 maximum predictors
regfit.interaction <- regsubsets(glucoseChange~.+carbohydrates:grain+glycemicIndex:fruit+glycemicIndex:inulin+AM:banana+fruit:banana+banana:glycemicIndex+diversity:carbohydrates+diversity:inulin,
                                 response_predictors, nvmax = ncol(response_predictors)-2)
reget.summary <- summary(regfit.interaction)


# Determine best set of variables
par(mfrow = c(1,3))
plot(reget.summary$adjr2, xlab = "Number of Variables", ylab = "Adjusted R^2", main = "Best Subset Selection")
points(which.max(reget.summary$adjr2), reget.summary$adjr2[which.max(reget.summary$adjr2)], 
       col = "red", cex = 2,pch = 20)
plot(reget.summary$cp, xlab = "Number of Variables", ylab = "Cp", main = "Best Subset Selection")
points(which.min(reget.summary$cp), reget.summary$cp[which.min(reget.summary$cp)], 
       col = "red", cex = 2,pch = 20)
plot(reget.summary$bic, xlab = "Number of Variables", ylab = "BIC", main = "Best Subset Selection")
points(which.min(reget.summary$bic), reget.summary$bic[which.min(reget.summary$bic)], 
       col = "red", cex = 2,pch = 20)

# determine which features to use
print(names(coef(regfit.interaction,which.min(reget.summary$cp)))[-1])

```

### Linear regression model
```{r linearRegression, message = F}

lm = lm(glucoseChange~AM+fruit+last_meal_TIME+diversity+inulin:diversity, data = response_predictors, subset = train)
summary_lm <- summary(lm)
print(summary_lm)

```

### LOOCV to determine RMSE
```{r lmLOOCV, message = F, collapse = T}
set.seed(1)
avg.AdjR2.lm = 0
avg.RMSE.lm = 0

for (i in 1:nrow(response_predictors)){
  test = i
  train = -i
  lm = lm(glucoseChange~AM+fruit+last_meal_TIME+diversity+inulin:diversity, data = response_predictors , subset = train)
  summary_lm <- summary(lm)

  pred.lm <- predict(lm,response_predictors[test,])
  MSE.lm <- mean((pred.lm - response_predictors[test,]$glucoseChange)^2)
  RMSE <- sqrt(MSE.lm)
  
  avg.RMSE.lm = avg.RMSE.lm + RMSE
  avg.AdjR2.lm = avg.AdjR2.lm + summary_lm$adj.r.squared  
  
}

LM.RMSE = round(avg.RMSE.lm/nrow(response_predictors),2)
print(paste("LOOCV RMSE LM:",LM.RMSE) )

```

</br>

# K-nearest Neighbor
```{r kNearestNeighbor}

## LOOCV cross validation
set.seed(0)
CV.kknn.interactions <- train.kknn(glucoseChange~.+carbohydrates:grain+glycemicIndex:fruit+glycemicIndex:inulin+AM:banana+fruit:banana+banana:glycemicIndex+diversity:carbohydrates+diversity:inulin, response_predictors, distance = 2, kmax = 21, kernel = "optimal")

# plot MSE and elbow method to determine K
par(mfrow = c(1,1))
plot(CV.kknn.interactions, main = "Optimizing for K") #, xlab = "Numnber of Clusters",ylab = "RSE")
number.clusters = 5
points(number.clusters, CV.kknn.interactions$MEAN.SQU[number.clusters], col = "red", pch = 20)


# print RMSE for LOOCV
knn.RMSE = round(sqrt(CV.kknn.interactions$MEAN.SQU[number.clusters]), 2)
print(paste("LOOCV KNN RMSE:", knn.RMSE))


```
</br>

# Random Forest
```{r randomForest, eval = F}
## calculate the average RSE for Leave out out 
set.seed(1)
avg.RMSE.RF = 0
avg.importance = rep(0,ncol(response_predictors)-1)

for(i in 1:nrow(response_predictors)){
  train = -i
  test = i
  test.set = 
    
    RF.glucoseChange = randomForest(glucoseChange~.+carbohydrates:grain+glycemicIndex:fruit+glycemicIndex:inulin+AM:banana+fruit:banana+banana:glycemicIndex+diversity:carbohydrates+diversity:inulin,
                                    data = response_predictors, subset = train, mtry = sqrt(ncol(response_predictors)-1), importance = TRUE)
  
  # calculate MSE
  pred.RF = predict(RF.glucoseChange ,newdata=response_predictors[test,])
  MSE.RF <- mean((pred.RF-response_predictors[test,]$glucoseChange)^2)
  RMSE = sqrt(MSE.RF)
  
  avg.RMSE.RF = avg.RMSE.RF + RMSE
  avg.importance = avg.importance + importance(RF.glucoseChange)[,1]
  
}

RF.RMSE = round(avg.RMSE.RF/nrow(response_predictors),2)
print(paste("Avg RMSE Random Forest:",RF.RMSE ))
```

### variable importance RF
```{r varImportanceRF, collapse=T, eval = F}
# set up dataset
variable.decrease = data.frame(variable = names(avg.importance), mean.decrease = avg.importance/nrow(response_predictors))
variable.order = variable.decrease[order(variable.decrease$mean.decrease), ]$variable

# plot decrease in accuracy
ggplot(variable.decrease) + 
  aes(y = mean.decrease, x = factor(variable, levels = variable.order)) + 
  geom_bar(stat = "identity", fill = "blue") + 
  coord_flip() + 
  labs(x = "variable name", y = "mean decrease in accuracy when left out of bag")

# plot variable importance plots
varImpPlot(RF.glucoseChange,main = "Variable Importance for Random Forest")

```


</br>

# Boosting

### optimize tuning parameter
```{r boostingTuning, collapse = T, eval = F}
set.seed(1)
train = sample(1:nrow(response_predictors), nrow(response_predictors)*0.75)
test = (-train)

minLambda = 7
minRMSE = 100

for (lambda in seq(0.000,0.005,0.001)){
  boost.glucoseChange <- gbm(glucoseChange~.+carbohydrates:grain+glycemicIndex:fruit+glycemicIndex:inulin+AM:banana+fruit:banana+banana:glycemicIndex+diversity:carbohydrates+diversity:inulin,
                             data = response_predictors[train,], distribution = "gaussian",
                             n.trees = 5000, interaction.depth = 4,
                             verbose = F,shrinkage = lambda)
  pred.boost <- predict(boost.glucoseChange, newdata = response_predictors[test,], n.trees = 5000)
  RMSE.boost <- sqrt(mean((pred.boost-response_predictors[test,]$glucoseChange)^2))
  
  
  if (RMSE.boost < minRMSE){
    # print(c("lambda",lambda,"MSE",RMSE.boost,minRMSE))
    minLambda = lambda
    minRMSE = RMSE.boost
  }
  
}

print(paste("best tuning parameter:", minLambda))
```

### optimize number of trees
```{r treesBoosting, collapse = T, eval = F}
numTrees = seq(0,20000,5000)
tree_RMSE = rep(0, length(numTrees))

i = 1
for (trees in numTrees){
  ## Find the model using all predictors to make plots
  boost.glucoseChange <- gbm(glucoseChange~.+carbohydrates:grain+glycemicIndex:fruit+glycemicIndex:inulin+AM:banana+fruit:banana+banana:glycemicIndex+diversity:carbohydrates+diversity:inulin,
                             data = response_predictors, distribution = "gaussian",
                             n.trees = trees, interaction.depth = 4,
                             verbose = F, shrinkage = minLambda)
  
  pred.boost <- predict(boost.glucoseChange, newdata = response_predictors[test,], n.trees = trees)
  tree_RMSE[i] <- sqrt(mean((pred.boost-response_predictors[test,]$glucoseChange)^2))
  i = i + 1 
}

# effect of number of trees
par(mfrow = c(1,1))
plot(numTrees,tree_RMSE, main = "Effect of Boosting with more Trees", ylab = "RMSE", xlab = "Number of Trees", pch = 16)
# lines(numTrees,tree_RMSE)
```

### plot relative importance
```{r boostingFactorsImportance, collapse = T, eval = F}

# relative importance of factors
boost.summary = summary(boost.glucoseChange, plotit = F)
ggplot(boost.summary) + 
  aes(x = factor(var, levels = rev(boost.summary$var)), 
      y = rel.inf) + 
  geom_bar(stat="identity", fill = "blue") + 
  labs(x = "model feature", y = "relative importance") + 
  coord_flip()

```
### plot marginal effects
```{r boostMarginalEffects, collapse=T, eval = F}
par(mfrow = c(2,2))
plot(boost.glucoseChange, i = "timeChange")
plot(boost.glucoseChange, i = "last_meal_TIME")
plot(boost.glucoseChange, i = "carbohydrates")
plot(boost.glucoseChange, i = "glycemicIndex")

```



# LOOCV to determine RMSE
```{r boostingRMSE, eval = F, tidy = T}

avg.RMSE.boost = 0

for (i in 1:nrow(response_predictors)){
  test = i
  train = -i
  
  ## Find the model using all predictors to make plots
  boost.glucoseChange <- gbm(glucoseChange~.+carbohydrates:grain+glycemicIndex:fruit+glycemicIndex:inulin+AM:banana+fruit:banana+banana:glycemicIndex+diversity:carbohydrates+diversity:inulin,
                             data = response_predictors[train,], distribution = "gaussian",
                             n.trees = 5000, interaction.depth = 4,
                             verbose = F,shrinkage = minLambda)
  
  
  pred.boost <- predict(boost.glucoseChange, newdata = response_predictors[test,], n.trees = 5000)
  MSE.boost <- mean((pred.boost-response_predictors[test,]$glucoseChange)^2)
  RMSE.boost = sqrt(MSE.boost)
  
  avg.RMSE.boost = avg.RMSE.boost + RMSE.boost
}

boosting.RMSE = round(avg.RMSE.boost/nrow(response_predictors),2)
print(paste("Average RMSE for Boosting: ",boosting.RMSE))

```

# LOOCV RMSE Results
```{r rmseResults, eval = F}

RMSE.results = data.frame(model = c("linear regression", "k-nearest neighbor (k = 5)",
                                           "random forest", "boosting random forest"),
                        RMSE = c(LM.RMSE, knn.RMSE, RF.RMSE, boosting.RMSE))
RMSE.results$`percent error` = round(RMSE.results$RMSE/mean(response_predictors$glucoseChange)*100,1)


# plot the RMSE for comparison
grid.newpage()
table.plot = tableGrob(RMSE.results, rows = NULL)
table.plot <- gtable_add_grob(table.plot,
                     grobs = rectGrob(gp = gpar(fill = NA, lwd = 2)),
                     t = 2, b = nrow(table.plot), l = 1, r = ncol(table.plot))
table.plot <- gtable_add_grob(table.plot,
                     grobs = rectGrob(gp = gpar(fill = NA, lwd = 2)),
                     t = 1, l = 1, r = ncol(table.plot))
grid.draw(table.plot)

```

## Session information

<!-- Insert the session information into the document -->
```{r session-info}
```
